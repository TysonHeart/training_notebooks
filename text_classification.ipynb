{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM65wJmeV6ZTBm/1xg/df3X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TysonHeart/training_notebooks/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzeHnaxAVvBT",
        "outputId": "2b2b2daf-de91-4985-ead1-2071075b5d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "\n",
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
        "                                    untar=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(dataset_dir)\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)\n",
        "\n",
        "sample_file = os.path.join(train_dir, 'pos/1181_9.txt')\n",
        "with open(sample_file) as f:\n",
        "  print(f.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZUjzC1TWT4r",
        "outputId": "a4013c29-67bf-4f91-db8a-d48d90f6d025"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "metadata": {
        "id": "JM3_JyYwXBSc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed)\n",
        "\n",
        "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
        "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])\n",
        "\n",
        "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed)\n",
        "\n",
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/test',\n",
        "    batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnjGp5r6XZtO",
        "outputId": "834e6edd-7492-46fe-f483-07e3c4e244e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Label 0 corresponds to neg\n",
            "Label 1 corresponds to pos\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation),\n",
        "                                  '')\n",
        "\n",
        "\n",
        "max_features = 10000\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "# Make a text-only dataset (without labels), then call adapt\n",
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)\n"
      ],
      "metadata": {
        "id": "246iljmOace9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label\n",
        "\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "pNP6WWgudz6w"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 16\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Embedding(max_features, embedding_dim),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcMWUlRMfDB2",
        "outputId": "e8ac0cfb-c135-4251-a2a1-84b6e150cd17"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 16)          160000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, None, 16)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 16)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160017 (625.07 KB)\n",
            "Trainable params: 160017 (625.07 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=losses.BinaryCrossentropy(),\n",
        "              optimizer='adam',\n",
        "              metrics=[tf.metrics.BinaryAccuracy(threshold=0.5)])\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"BEfORE FIT\")\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"AFTER FIT\")\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGYRQ9AugHBM",
        "outputId": "6913c531-cc06-4473-a6ab-f6319d6fe43c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6931 - binary_accuracy: 0.5075\n",
            "BEfORE FIT\n",
            "Loss:  0.6930965781211853\n",
            "Accuracy:  0.5074800252914429\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 11s 16ms/step - loss: 0.6619 - binary_accuracy: 0.6956 - val_loss: 0.6114 - val_binary_accuracy: 0.7734\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.5461 - binary_accuracy: 0.8027 - val_loss: 0.4957 - val_binary_accuracy: 0.8232\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.4422 - binary_accuracy: 0.8449 - val_loss: 0.4183 - val_binary_accuracy: 0.8468\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.3770 - binary_accuracy: 0.8675 - val_loss: 0.3726 - val_binary_accuracy: 0.8610\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.3344 - binary_accuracy: 0.8787 - val_loss: 0.3445 - val_binary_accuracy: 0.8682\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.3044 - binary_accuracy: 0.8884 - val_loss: 0.3253 - val_binary_accuracy: 0.8724\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2808 - binary_accuracy: 0.8982 - val_loss: 0.3123 - val_binary_accuracy: 0.8734\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2610 - binary_accuracy: 0.9046 - val_loss: 0.3032 - val_binary_accuracy: 0.8770\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.2447 - binary_accuracy: 0.9108 - val_loss: 0.2965 - val_binary_accuracy: 0.8788\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2302 - binary_accuracy: 0.9154 - val_loss: 0.2922 - val_binary_accuracy: 0.8800\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.3098 - binary_accuracy: 0.8740\n",
            "AFTER FIT\n",
            "Loss:  0.30980947613716125\n",
            "Accuracy:  0.8740400075912476\n"
          ]
        }
      ]
    }
  ]
}